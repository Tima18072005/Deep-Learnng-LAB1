{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":14957854,"datasetId":9573958,"databundleVersionId":15828758}],"dockerImageVersionId":31287,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import albumentations as A\nimport cv2\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport timm\nimport os\nimport random\nfrom collections import defaultdict\nfrom glob import glob\nfrom tqdm import tqdm\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T23:00:37.687007Z","iopub.execute_input":"2026-02-25T23:00:37.687430Z","iopub.status.idle":"2026-02-25T23:00:53.431925Z","shell.execute_reply.started":"2026-02-25T23:00:37.687400Z","shell.execute_reply":"2026-02-25T23:00:53.431300Z"},"id":"pYxm6D8rE63K","outputId":"b6ca1862-f900-45e8-ee6d-03c7e4deccf1"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_path = \"/kaggle/input/datasets/iowiqo/lab1vegs/imgs/\"","metadata":{"id":"NV3y2IkAJqhC","trusted":true,"execution":{"iopub.status.busy":"2026-02-26T07:38:33.827598Z","iopub.execute_input":"2026-02-26T07:38:33.828290Z","iopub.status.idle":"2026-02-26T07:38:33.831991Z","shell.execute_reply.started":"2026-02-26T07:38:33.828264Z","shell.execute_reply":"2026-02-26T07:38:33.830980Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# –≤–∞–∂–Ω–æ - –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ —Å–∏–¥—ã\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T23:00:53.438292Z","iopub.execute_input":"2026-02-25T23:00:53.438609Z","iopub.status.idle":"2026-02-25T23:00:53.589089Z","shell.execute_reply.started":"2026-02-25T23:00:53.438577Z","shell.execute_reply":"2026-02-25T23:00:53.588273Z"},"id":"tFEy9pKqE63K"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_to_idx = {\n  \"–ê–ø–µ–ª—å—Å–∏–Ω—ã\": 0,\n  \"–ë–∞–Ω–∞–Ω—ã\": 1,\n  \"–ì—Ä—É—à–∏\": 2,\n  \"–ö–∞–±–∞—á–∫–∏\": 3,\n  \"–ö–∞–ø—É—Å—Ç–∞\": 4,\n  \"–ö–∞—Ä—Ç–æ—Ñ–µ–ª—å\": 5,\n  \"–ö–∏–≤–∏\": 6,\n  \"–õ–∏–º–æ–Ω\": 7,\n  \"–õ—É–∫\": 8,\n  \"–ú–∞–Ω–¥–∞—Ä–∏–Ω—ã\": 9,\n  \"–ú–æ—Ä–∫–æ–≤—å\": 10,\n  \"–û–≥—É—Ä—Ü—ã\": 11,\n  \"–¢–æ–º–∞—Ç—ã\": 12,\n  \"–Ø–±–ª–æ–∫–∏ –∑–µ–ª—ë–Ω—ã–µ\": 13,\n  \"–Ø–±–ª–æ–∫–∏ –∫—Ä–∞—Å–Ω—ã–µ\": 14\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T23:00:53.589990Z","iopub.execute_input":"2026-02-25T23:00:53.590238Z","iopub.status.idle":"2026-02-25T23:00:53.594691Z","shell.execute_reply.started":"2026-02-25T23:00:53.590216Z","shell.execute_reply":"2026-02-25T23:00:53.593785Z"},"id":"dV5KmvtEE63L"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class EMA:\n    def __init__(self, model, decay=0.999):\n        self.model = model\n        self.decay = decay\n        self.shadow = {}\n        self.backup = {}\n        self.register()\n\n    def register(self):\n        for name, param in self.model.named_parameters():\n            if param.requires_grad:\n                self.shadow[name] = param.data.clone()\n\n    def update(self, model=None):\n        if model is None:\n            model = self.model\n        for name, param in model.named_parameters():\n            if param.requires_grad:\n                new_average = (1.0 - self.decay) * param.data + self.decay * self.shadow[name]\n                self.shadow[name] = new_average.clone()\n\n    def apply_shadow(self):\n        for name, param in self.model.named_parameters():\n            if param.requires_grad:\n                self.backup[name] = param.data\n                param.data = self.shadow[name]\n\n    def restore(self):\n        for name, param in self.model.named_parameters():\n            if param.requires_grad:\n                param.data = self.backup[name]\n        self.backup = {}\n        \n    @property\n    def ema(self):\n        return self.model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T23:00:53.596583Z","iopub.execute_input":"2026-02-25T23:00:53.596877Z","iopub.status.idle":"2026-02-25T23:00:53.608910Z","shell.execute_reply.started":"2026-02-25T23:00:53.596853Z","shell.execute_reply":"2026-02-25T23:00:53.608304Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, images_filepaths, name2label,\n                 base_transform=None,\n                 strong_transform=None,\n                 weak_classes=None):\n        \"\"\"\n        images_filepaths: —Å–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∏–ª–∏ –∫–æ—Ä—Ç–µ–∂–µ–π (path, label)\n        name2label: —Å–ª–æ–≤–∞—Ä—å –∏–º—è –∫–ª–∞—Å—Å–∞ -> –∏–Ω–¥–µ–∫—Å (–¥–ª—è —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –µ—Å–ª–∏ paths –±–µ–∑ –º–µ—Ç–æ–∫)\n        –ï—Å–ª–∏ images_filepaths —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ—Ä—Ç–µ–∂–∏ (path, label), —Ç–æ name2label –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç—Å—è.\n        \"\"\"\n        self.images_filepaths = images_filepaths\n        self.name2label = name2label\n        self.base_transform = base_transform\n        self.strong_transform = strong_transform\n        self.weak_classes = weak_classes or []\n\n    def __len__(self):\n        return len(self.images_filepaths)\n\n    def __getitem__(self, idx):\n        # –ï—Å–ª–∏ images_filepaths —Ö—Ä–∞–Ω–∏—Ç –∫–æ—Ä—Ç–µ–∂–∏ (path, label)\n        if isinstance(self.images_filepaths[idx], (tuple, list)):\n            image_filepath, label = self.images_filepaths[idx]\n        else:\n            # –°—Ç–∞—Ä—ã–π –≤–∞—Ä–∏–∞–Ω—Ç: —Ç–æ–ª—å–∫–æ –ø—É—Ç—å, –º–µ—Ç–∫–∞ –∏–∑ name2label\n            image_filepath = self.images_filepaths[idx]\n            label = self.name2label[os.path.normpath(image_filepath).split(os.sep)[-3]]\n\n        image = cv2.imdecode(np.fromfile(image_filepath, dtype=np.uint8), cv2.IMREAD_UNCHANGED)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        # –í—ã–±–æ—Ä –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ pipeline\n        if label in self.weak_classes:\n            transform = self.strong_transform\n        else:\n            transform = self.base_transform\n\n        if transform is not None:\n            image = transform(image=image)['image']\n\n        return image, label\n\n\ndef train_test_split_from_directory(root_path, folder2class, train_size=0.8):\n    train, test = [], []\n    class_to_images = defaultdict(list)\n\n    for class_name in os.listdir(root_path):\n        class_path = os.path.join(root_path, class_name)\n        if not os.path.isdir(class_path):\n            continue\n\n        for subclass_name in os.listdir(class_path):\n            subclass_path = os.path.join(class_path, subclass_name)\n            if not os.path.isdir(subclass_path):\n                continue\n\n            # –ì–ª–æ–±–∞–ª—å–Ω—ã–π –∫–ª–∞—Å—Å = –∏–º—è –ø–µ—Ä–≤–æ–π –ø–∞–ø–∫–∏ (class_name)\n            class_name = folder2class.get(class_name, class_name)\n\n            images = glob(os.path.join(subclass_path, '*.jpg')) + \\\n                     glob(os.path.join(subclass_path, '*.png')) + \\\n                     glob(os.path.join(subclass_path, '*.jpeg'))\n\n            class_to_images[class_name].extend(images)\n\n    # –†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –ø–æ –∫–∞–∂–¥–æ–º—É –∫–ª–∞—Å—Å—É\n    for cls_name, images in class_to_images.items():\n        random.shuffle(images)\n        split_idx = int(train_size * len(images))\n        train.extend(images[:split_idx])\n        test.extend(images[split_idx:])\n\n    return train, test\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T23:00:53.609884Z","iopub.execute_input":"2026-02-25T23:00:53.610396Z","iopub.status.idle":"2026-02-25T23:00:53.626021Z","shell.execute_reply.started":"2026-02-25T23:00:53.610365Z","shell.execute_reply":"2026-02-25T23:00:53.625410Z"},"id":"wZ2s4wgdE63L"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom collections import Counter\n\n# –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –ø–∞–ø–∫–∏ train\nall_images = []\nall_labels = []\n\ndataset_path = base_path + 'train'\nfor class_name in os.listdir(dataset_path):\n    class_path = os.path.join(dataset_path, class_name)\n    if not os.path.isdir(class_path):\n        continue\n    # –ï—Å–ª–∏ –µ—Å—Ç—å –ø–æ–¥–ø–∞–ø–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ä–∞–∑–Ω—ã–µ –ø–∞—Ä—Ç–∏–∏)\n    for subclass_name in os.listdir(class_path):\n        subclass_path = os.path.join(class_path, subclass_name)\n        if not os.path.isdir(subclass_path):\n            continue\n        class_idx = class_to_idx.get(class_name)\n        if class_idx is None:\n            print(f\"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∫–ª–∞—Å—Å {class_name}\")\n            continue\n        images = glob(os.path.join(subclass_path, '*.jpg')) + \\\n                 glob(os.path.join(subclass_path, '*.png')) + \\\n                 glob(os.path.join(subclass_path, '*.jpeg'))\n        for img_path in images:\n            all_images.append(img_path)\n            all_labels.append(class_idx)\n\nprint(f\"–í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(all_images)}\")\nprint(f\"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤: {dict(Counter(all_labels))}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T23:00:53.627080Z","iopub.execute_input":"2026-02-25T23:00:53.627779Z","iopub.status.idle":"2026-02-25T23:00:59.775425Z","shell.execute_reply.started":"2026-02-25T23:00:53.627750Z","shell.execute_reply":"2026-02-25T23:00:59.774629Z"},"id":"c4U0VnxzE63L"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# –í–µ—Å–∞ –¥–ª—è –∫–ª–∞—Å—Å–æ–≤ —Å —É—á—ë—Ç–æ–º –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ –∏ —É—Å–∏–ª–µ–Ω–∏–µ–º —Å–ª–∞–±—ã—Ö –∫–ª–∞—Å—Å–æ–≤\nnum_classes = len(class_to_idx)\nclass_weights = torch.zeros(num_classes)\n\ntrain_counts_dict = dict(Counter(all_labels))\nmax_count = max(train_counts_dict.values()) if train_counts_dict else 1\n\n# –ë–∞–∑–æ–≤—ã–µ –≤–µ—Å–∞ ‚Äì –æ–±—Ä–∞—Ç–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞\nfor i in range(num_classes):\n    count = train_counts_dict.get(i, 0)\n    if count > 0:\n        class_weights[i] = max_count / count\n    else:\n        class_weights[i] = 0.0\n\nprint(\"Raw class weights (inverse frequency):\", class_weights.cpu().numpy())\n\n# –ù–æ—Ä–º–∏—Ä–æ–≤–∫–∞, —á—Ç–æ–±—ã —Å—É–º–º–∞ —Ä–∞–≤–Ω—è–ª–∞—Å—å num_classes\nclass_weights = class_weights / class_weights.sum() * num_classes\n\n# –°–ø–∏—Å–æ–∫ —Å–ª–∞–±—ã—Ö –∫–ª–∞—Å—Å–æ–≤ (—Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–π—Ç–µ –ø–æ–¥ –≤–∞—à–∏ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è)\nWEAK_CLASSES = [0, 2, 6, 8, 14]  # –ê–ø–µ–ª—å—Å–∏–Ω—ã, –ì—Ä—É—à–∏, –ö–∏–≤–∏, –õ—É–∫, –Ø–±–ª–æ–∫–∏ –∫—Ä–∞—Å–Ω—ã–µ\nBOOST_FACTOR = 1.2  # –≤–æ —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ —É–≤–µ–ª–∏—á–∏—Ç—å –≤–µ—Å –¥–ª—è —ç—Ç–∏—Ö –∫–ª–∞—Å—Å–æ–≤\n\nfor i in WEAK_CLASSES:\n    class_weights[i] *= BOOST_FACTOR\n\n# –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –Ω–æ—Ä–º–∏—Ä–æ–≤–∫–∞ –ø–æ—Å–ª–µ —É—Å–∏–ª–µ–Ω–∏—è\nclass_weights = class_weights / class_weights.sum() * num_classes\n\nprint(\"Class weights after boosting weak classes:\", class_weights.cpu().numpy())\n\n# –ü–µ—Ä–µ–Ω–µ—Å–∏—Ç–µ —ç—Ç—É —Å—Ç—Ä–æ–∫—É –ü–û–ó–ñ–ï, –ø–æ—Å–ª–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è device\n# class_weights = class_weights.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T23:00:59.776448Z","iopub.execute_input":"2026-02-25T23:00:59.776847Z","iopub.status.idle":"2026-02-25T23:00:59.845994Z","shell.execute_reply.started":"2026-02-25T23:00:59.776820Z","shell.execute_reply":"2026-02-25T23:00:59.845105Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# –í–µ—Ä–Ω—ë–º—Å—è –∫ –æ–±—É—á–µ–Ω–∏—é","metadata":{"id":"-jVCVJWuE63M"}},{"cell_type":"markdown","source":"### –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏","metadata":{"id":"S47EKxc6E63M"}},{"cell_type":"code","source":"def create_tta_batch(x: torch.Tensor):\n    # x: shape (B, C, H, W)\n    tta_versions = []\n\n    tta_versions.append(x)\n    tta_versions.append(torch.flip(x, dims=[3]))\n    tta_versions.append(torch.flip(x, dims=[2]))\n    tta_versions.append(torch.flip(x, dims=[2, 3]))\n    tta_versions.append(torch.rot90(x, k=1, dims=[2, 3]))\n    tta_versions.append(torch.rot90(x, k=2, dims=[2, 3]))\n    tta_versions.append(torch.rot90(x, k=3, dims=[2, 3]))\n\n    tta_batch = torch.cat(tta_versions, dim=0) # shape: (B*n_tta, C, H, W)\n    return tta_batch, len(tta_versions)\n\ndef calc_tta_logits(model, X_batch):\n    tta_batch, n_tta = create_tta_batch(X_batch) # shape: (B*n_tta, C, H, W)\n    logits_all = model(tta_batch)  # shape: (B*n_tta, num_classes)\n\n    B = X_batch.size(0)\n\n    logits_all = logits_all.view(n_tta, B, -1) # shape: (n_tta, B, num_classes)\n    logits = logits_all.mean(dim=0)  # shape: (B, num_classes)\n    return logits\n","metadata":{"id":"fnCl-6b_nQm_","trusted":true,"execution":{"iopub.status.busy":"2026-02-25T23:00:59.847074Z","iopub.execute_input":"2026-02-25T23:00:59.847380Z","iopub.status.idle":"2026-02-25T23:00:59.853720Z","shell.execute_reply.started":"2026-02-25T23:00:59.847312Z","shell.execute_reply":"2026-02-25T23:00:59.852998Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def mixup_data(x, y, alpha=0.2):\n    \"\"\"\n    –°–æ–∑–¥–∞—ë—Ç —Å–º–µ—à–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –º–µ—Ç–∫–∏.\n    x: –±–∞—Ç—á –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (B, C, H, W)\n    y: –±–∞—Ç—á –º–µ—Ç–æ–∫ (B,) –∏–ª–∏ one-hot\n    alpha: –ø–∞—Ä–∞–º–µ—Ç—Ä –±–µ—Ç–∞-—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è\n    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:\n        mixed_x: —Å–º–µ—à–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n        y_a, y_b: –∏—Å—Ö–æ–¥–Ω—ã–µ –º–µ—Ç–∫–∏ –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –∏ –≤—Ç–æ—Ä–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n        lam: –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–º–µ—à–∏–≤–∞–Ω–∏—è\n    \"\"\"\n    if alpha > 0:\n        lam = np.random.beta(alpha, alpha)\n    else:\n        lam = 1\n\n    batch_size = x.size(0)\n    index = torch.randperm(batch_size).to(x.device)\n\n    mixed_x = lam * x + (1 - lam) * x[index]\n    y_a, y_b = y, y[index]\n\n    return mixed_x, y_a, y_b, lam\n\ndef mixup_criterion(criterion, pred, y_a, y_b, lam):\n    \"\"\"\n    –ö—Ä–∏—Ç–µ—Ä–∏–π –¥–ª—è MixUp: –≤–∑–≤–µ—à–µ–Ω–Ω–∞—è —Å—É–º–º–∞ –ø–æ—Ç–µ—Ä—å –¥–ª—è –¥–≤—É—Ö –Ω–∞–±–æ—Ä–æ–≤ –º–µ—Ç–æ–∫.\n    criterion: —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∞—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –≤—ã–∑–æ–≤ (pred, target)\n    pred: –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏\n    y_a, y_b: –∏—Å—Ö–æ–¥–Ω—ã–µ –º–µ—Ç–∫–∏\n    lam: –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–º–µ—à–∏–≤–∞–Ω–∏—è\n    \"\"\"\n    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T23:00:59.854591Z","iopub.execute_input":"2026-02-25T23:00:59.854845Z","iopub.status.idle":"2026-02-25T23:00:59.869189Z","shell.execute_reply.started":"2026-02-25T23:00:59.854821Z","shell.execute_reply":"2026-02-25T23:00:59.868487Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ---------- –ù–û–í–´–ô –ë–õ–û–ö: –Ω–µ—Å–∫–æ–ª—å–∫–æ pipeline'–æ–≤ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π ----------\n# –ò–Ω–¥–µ–∫—Å—ã –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤ (–∏–∑ class_to_idx)\nWEAK_CLASSES = [0, 2, 6, 8, 14]       # –ê–ø–µ–ª—å—Å–∏–Ω—ã, –ì—Ä—É—à–∏, –ö–∏–≤–∏, –õ—É–∫, –Ø–±–ª–æ–∫–∏ –∫—Ä–∞—Å–Ω—ã–µ\n\nIMAGE_W, IMAGE_H = 320, 320\n\n# –ë–∞–∑–æ–≤—ã–π pipeline (–¥–ª—è –≤—Å–µ—Ö, –∫—Ä–æ–º–µ –æ—Å–æ–±—ã—Ö —Å–ª—É—á–∞–µ–≤)\nbase_train_transforms = A.Compose([\n    A.Resize(IMAGE_W, IMAGE_H),\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.3),\n    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.15, rotate_limit=30, p=0.5),\n    A.GridDropout(ratio=0.2, p=0.2),\n    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    A.ToTensorV2(),\n])\n\n# –£—Å–∏–ª–µ–Ω–Ω—ã–π pipeline –¥–ª—è —Å–ª–∞–±—ã—Ö –∫–ª–∞—Å—Å–æ–≤ (–±–æ–ª—å—à–µ –≥–µ–æ–º–µ—Ç—Ä–∏–∏, Cutout, —à—É–º)\nstrong_transforms = A.Compose([\n    A.Resize(IMAGE_W, IMAGE_H),\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.RandomRotate90(p=0.5),\n    A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=45, p=0.7),\n    A.GridDropout(ratio=0.25, p=0.25),\n    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    A.ToTensorV2(),\n])\n\n# –î–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –æ—Å—Ç–∞–≤–ª—è–µ–º –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π (—Ç–æ–ª—å–∫–æ Resize + Normalize)\nval_transforms = A.Compose([\n    A.Resize(IMAGE_W, IMAGE_H),\n    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    A.ToTensorV2(),\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T23:00:59.869887Z","iopub.execute_input":"2026-02-25T23:00:59.870082Z","iopub.status.idle":"2026-02-25T23:00:59.889392Z","shell.execute_reply.started":"2026-02-25T23:00:59.870064Z","shell.execute_reply":"2026-02-25T23:00:59.888663Z"},"id":"3CaTzHylE63M","outputId":"b38ff1c3-b868-4c08-c228-a2443493858f"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"@torch.no_grad()\ndef evaluate(model, dataloader, loss_fn, device, desc=\"Val\"):\n    model.eval()\n\n    total_loss = 0.0\n    total_correct = 0\n    total_samples = 0\n\n    pbar = tqdm(dataloader, desc=desc, leave=False)\n    for X_batch, y_batch in pbar:\n        X_batch = X_batch.to(device)\n        y_batch = y_batch.to(device)\n\n        logits = calc_tta_logits(model, X_batch)\n        loss = loss_fn(logits, y_batch)\n\n        batch_size = y_batch.size(0)\n        total_loss += loss.item() * batch_size\n\n        y_pred = logits.argmax(dim=1)\n        total_correct += (y_pred == y_batch).sum().item()\n        total_samples += batch_size\n\n        avg_loss = total_loss / max(total_samples, 1)\n        acc = total_correct / max(total_samples, 1)\n        pbar.set_postfix(loss=f\"{avg_loss:.4f}\", acc=f\"{acc:.4f}\")\n\n    avg_loss = total_loss / max(total_samples, 1)\n    accuracy = total_correct / max(total_samples, 1)\n    return accuracy, avg_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T23:00:59.890475Z","iopub.execute_input":"2026-02-25T23:00:59.890782Z","iopub.status.idle":"2026-02-25T23:00:59.897546Z","shell.execute_reply.started":"2026-02-25T23:00:59.890751Z","shell.execute_reply":"2026-02-25T23:00:59.896721Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train(model, loss_fn, optimizer, scheduler, train_loader, val_loader, device, \n          ema=None, writer=None, n_epoch=10, save_path=\"best_model.pth\"):\n    num_iter = 0\n    best_val_acc = 0.0\n    patience = 5\n    patience_counter = 0\n    \n    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã MixUp\n    mixup_alpha = 0.1\n    mixup_prob = 0.5\n\n    for epoch in range(1, n_epoch + 1):\n        model.train()\n\n        total_loss = 0.0\n        clean_correct = 0\n        clean_samples = 0\n        num_batches = 0\n\n        pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{n_epoch}\", leave=True)\n\n        for X_batch, y_batch in pbar:\n            X_batch = X_batch.to(device, non_blocking=True)\n            y_batch = y_batch.to(device, non_blocking=True)\n\n            # –°–ª—É—á–∞–π–Ω–æ —Ä–µ—à–∞–µ–º, –ø—Ä–∏–º–µ–Ω—è—Ç—å –ª–∏ MixUp\n            use_mixup = random.random() < mixup_prob\n\n            if use_mixup:\n                X_batch, y_a, y_b, lam = mixup_data(X_batch, y_batch, alpha=mixup_alpha)\n                logits = model(X_batch)\n                loss = mixup_criterion(loss_fn, logits, y_a, y_b, lam)\n                # –î–ª—è –±–∞—Ç—á–µ–π —Å MixUp –Ω–µ –æ–±–Ω–æ–≤–ª—è–µ–º accuracy\n            else:\n                logits = model(X_batch)\n                loss = loss_fn(logits, y_batch)\n                \n                # –°—á–∏—Ç–∞–µ–º accuracy —Ç–æ–ª—å–∫–æ –Ω–∞ —á–∏—Å—Ç—ã—Ö –±–∞—Ç—á–∞—Ö\n                y_pred = logits.argmax(dim=1)\n                clean_correct += (y_pred == y_batch).sum().item()\n                clean_samples += y_batch.size(0)\n\n            optimizer.zero_grad(set_to_none=True)\n            loss.backward()\n            optimizer.step()\n            \n            if ema is not None:\n                ema.update(model)\n\n            # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏\n            batch_size = X_batch.size(0)\n            total_loss += loss.item() * batch_size\n            num_batches += 1\n            \n            avg_loss = total_loss / (num_batches * train_loader.batch_size)\n            clean_acc = clean_correct / max(clean_samples, 1)\n            \n            pbar.set_postfix(\n                train_loss=f\"{avg_loss:.4f}\", \n                train_acc=f\"{clean_acc:.4f}\",\n                mixup=f\"{use_mixup}\"\n            )\n\n            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ\n            num_iter += 1\n            if writer is not None:\n                writer.add_scalar(\"Loss/train\", loss.item(), num_iter)\n                if not use_mixup:\n                    writer.add_scalar(\"Accuracy/train_clean\", (y_pred == y_batch).float().mean().item(), num_iter)\n\n        # –í–∞–ª–∏–¥–∞—Ü–∏—è (–∏—Å–ø–æ–ª—å–∑—É–µ–º EMA –º–æ–¥–µ–ª—å, –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å)\n        val_model = ema.ema if ema is not None else model\n        val_acc, val_loss = evaluate(val_model, val_loader, loss_fn, device, desc=f\"Val {epoch}/{n_epoch}\")\n        \n        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            patience_counter = 0\n            torch.save(val_model.state_dict(), save_path)\n            print(f\"üî• New best model saved! val_acc = {val_acc:.4f}\")\n        else:\n            patience_counter += 1\n\n        # –û–±–Ω–æ–≤–ª—è–µ–º scheduler\n        if scheduler is not None:\n            if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n                scheduler.step(val_loss)\n            else:\n                scheduler.step()\n            current_lr = scheduler.get_last_lr()[0]\n        else:\n            current_lr = optimizer.param_groups[0]['lr']\n\n        if writer is not None:\n            writer.add_scalar(\"Loss/val\", val_loss, num_iter)\n            writer.add_scalar(\"Accuracy/val\", val_acc, num_iter)\n            writer.add_scalar(\"LR\", current_lr, epoch)\n\n        # Early stopping\n        if patience_counter >= patience:\n            print(f\"‚õî Early stopping triggered. Best val_acc = {best_val_acc:.4f}\")\n            break\n\n        print(f\"Epoch {epoch}/{n_epoch}: val_loss={val_loss:.4f}  val_acc={val_acc:.4f}  lr={current_lr:.6f}\")\n\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T23:00:59.898630Z","iopub.execute_input":"2026-02-25T23:00:59.898895Z","iopub.status.idle":"2026-02-25T23:00:59.914299Z","shell.execute_reply.started":"2026-02-25T23:00:59.898874Z","shell.execute_reply":"2026-02-25T23:00:59.913716Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# –ù–ê–ß–ê–õ–û K-FOLD –û–ë–£–ß–ï–ù–ò–Ø\n# ============================================\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# –ü–µ—Ä–µ–Ω–æ—Å–∏–º –≤–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ\nclass_weights = class_weights.to(device)\n\n# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã K-Fold\nn_folds = 5\nskf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=SEED)\nEPOCHS_PER_FOLD = 30  # –º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å –¥–æ 50, –µ—Å–ª–∏ –ø–æ–∑–≤–æ–ª—è–µ—Ç –≤—Ä–µ–º—è\nBATCH_SIZE = 32  # \n\n# –°–ø–∏—Å–æ–∫ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—É—Ç–µ–π –∫ –ª—É—á—à–∏–º –º–æ–¥–µ–ª—è–º\nbest_model_paths = []\n\n# –¶–∏–∫–ª –ø–æ —Ñ–æ–ª–¥–∞–º\nfor fold, (train_idx, val_idx) in enumerate(skf.split(all_images, all_labels)):\n    print(f\"\\n{'='*60}\")\n    print(f\"Fold {fold+1}/{n_folds}\")\n    print(f\"{'='*60}\")\n    \n    # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —Ñ–æ–ª–¥–∞\n    train_data = [(all_images[i], all_labels[i]) for i in train_idx]\n    val_data = [(all_images[i], all_labels[i]) for i in val_idx]\n    \n    print(f\"Train samples: {len(train_data)}, Val samples: {len(val_data)}\")\n    \n    # –°–æ–∑–¥–∞—ë–º –¥–∞—Ç–∞—Å–µ—Ç—ã\n    train_dataset_fold = MyDataset(\n        images_filepaths=train_data,\n        name2label=None,\n        base_transform=base_train_transforms,\n        strong_transform=strong_transforms,\n        weak_classes=WEAK_CLASSES\n    )\n    \n    val_dataset_fold = MyDataset(\n        images_filepaths=val_data,\n        name2label=None,\n        base_transform=val_transforms,\n        strong_transform=val_transforms\n    )\n    \n    # –î–∞—Ç–∞–ª–æ–∞–¥–µ—Ä—ã\n    train_loader_fold = DataLoader(\n        train_dataset_fold,\n        batch_size=BATCH_SIZE,\n        shuffle=True,\n        num_workers=2,\n        pin_memory=True,\n        persistent_workers=True\n    )\n    \n    val_loader_fold = DataLoader(\n        val_dataset_fold,\n        batch_size=BATCH_SIZE // 2,\n        shuffle=False,\n        num_workers=2,\n        pin_memory=True,\n        persistent_workers=True\n    )\n    \n    # –°–æ–∑–¥–∞—ë–º –º–æ–¥–µ–ª—å –¥–ª—è —Ñ–æ–ª–¥–∞\n    model_fold = timm.create_model('tf_efficientnetv2_s', pretrained=True, num_classes=15, drop_rate=0.3)\n    model_fold.to(device)\n    \n    # Loss, –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä, scheduler, EMA\n    loss_fn_fold = torch.nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n    \n    optimizer_fold = torch.optim.AdamW(model_fold.parameters(), lr=1e-3, weight_decay=1e-4)\n    scheduler_fold = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer_fold, T_0=5, T_mult=1)\n    \n    ema_fold = EMA(model_fold, decay=0.999)\n    \n    # –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ —Ç–µ–∫—É—â–µ–≥–æ —Ñ–æ–ª–¥–∞\n    fold_save_path = f\"best_model_fold{fold}.pth\"\n    best_model_paths.append(fold_save_path)\n    \n    # –û–±—É—á–µ–Ω–∏–µ\n    train(\n        model=model_fold,\n        loss_fn=loss_fn_fold,\n        optimizer=optimizer_fold,\n        scheduler=scheduler_fold,\n        train_loader=train_loader_fold,\n        val_loader=val_loader_fold,\n        device=device,\n        ema=ema_fold,\n        writer=None,  # –º–æ–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å SummaryWriter –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ–æ–ª–¥–∞, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ\n        n_epoch=EPOCHS_PER_FOLD,\n        save_path=fold_save_path\n    )\n    \n    # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏\n    del model_fold, train_loader_fold, val_loader_fold, train_dataset_fold, val_dataset_fold\n    torch.cuda.empty_cache()\n    \nprint(\"\\n‚úÖ –í—Å–µ —Ñ–æ–ª–¥—ã –æ–±—É—á–µ–Ω—ã! –õ—É—á—à–∏–µ –º–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã.\")\nprint(\"–ü—É—Ç–∏ –∫ –º–æ–¥–µ–ª—è–º:\", best_model_paths)\n\n# ============================================\n# –ö–û–ù–ï–¶ K-FOLD –û–ë–£–ß–ï–ù–ò–Ø\n# ============================================","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T23:00:59.916534Z","iopub.execute_input":"2026-02-25T23:00:59.916816Z","iopub.status.idle":"2026-02-26T06:40:39.650153Z","shell.execute_reply.started":"2026-02-25T23:00:59.916780Z","shell.execute_reply":"2026-02-26T06:40:39.649394Z"},"id":"4Sae-5ybE63M"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# –ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –∏—Ç–æ–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏","metadata":{"id":"FCjxIQiyE63M"}},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n@torch.no_grad()\ndef sklearn_report(model, dataloader, device, idx2class=None, digits=4):\n    model.eval()\n\n    y_true, y_pred = [], []\n\n    for X_batch, y_batch in dataloader:\n        X_batch = X_batch.to(device, non_blocking=True)\n\n        logits = calc_tta_logits(model, X_batch)\n        preds = logits.argmax(dim=1).cpu().numpy()\n\n        y_pred.append(preds)\n        y_true.append(y_batch.numpy())\n\n    y_true = np.concatenate(y_true)\n    y_pred = np.concatenate(y_pred)\n\n    # names for report\n    if idx2class is None:\n        target_names = None\n        labels = None\n    else:\n        labels = sorted(idx2class.keys())\n        target_names = [idx2class[i] for i in labels]\n\n    rep = classification_report(\n        y_true, y_pred,\n        labels=labels,\n        target_names=target_names,\n        digits=digits,\n        zero_division=0\n    )\n    print(rep)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-26T06:40:39.651453Z","iopub.execute_input":"2026-02-26T06:40:39.651730Z","iopub.status.idle":"2026-02-26T06:40:39.658603Z","shell.execute_reply.started":"2026-02-26T06:40:39.651706Z","shell.execute_reply":"2026-02-26T06:40:39.658012Z"},"id":"XsKl4-xyE63M"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# –û—Ñ–æ—Ä–º–ª—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ","metadata":{"id":"Frx-2Zy0E63M"}},{"cell_type":"code","source":"# ============================================\n# –§–ò–ù–ê–õ–¨–ù–û–ï –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ï –° –ê–ù–°–ê–ú–ë–õ–ï–ú –ú–û–î–ï–õ–ï–ô\n# ============================================\ntest_images_dir = base_path + \"test_images\"\nsubmission_path = base_path + \"sample_submission.csv\"\noutput_path = \"/kaggle/working/submission.csv\"\n\nprint(f'test_images_dir({test_images_dir})')\nprint(f'submission_path({submission_path})')\n\nsubmission = pd.read_csv(submission_path)\nimage_ids = submission[\"image_id\"].tolist()\n\n# –°–ø–∏—Å–æ–∫ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –ª–æ–≥–∏—Ç–æ–≤ –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏\nall_fold_logits = []\n\nfor fold, model_path in enumerate(best_model_paths):\n    print(f\"\\nüì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Ñ–æ–ª–¥–∞ {fold} –∏–∑ {model_path}\")\n    \n    # –°–æ–∑–¥–∞—ë–º –º–æ–¥–µ–ª—å —Å —Ç–æ–π –∂–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π\n    model_fold = timm.create_model('tf_efficientnetv2_s', pretrained=False, num_classes=15)\n    model_fold.load_state_dict(torch.load(model_path, map_location='cpu'))\n    model_fold.eval().to(device)\n    \n    fold_logits = []\n    test_batch_size = 32  # —É–º–µ–Ω—å—à–∞–µ–º –¥–ª—è TTA\n    \n    with torch.no_grad():\n        for start_idx in tqdm(range(0, len(image_ids), test_batch_size), desc=f\"Predicting fold {fold}\"):\n            batch_ids = image_ids[start_idx:start_idx + test_batch_size]\n            images = []\n            \n            for image_id in batch_ids:\n                image_path = os.path.join(test_images_dir, image_id)\n                image = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_COLOR)\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                image = val_transforms(image=image)[\"image\"]\n                images.append(image)\n            \n            X_batch = torch.stack(images).to(device, non_blocking=True)\n            logits = calc_tta_logits(model_fold, X_batch)  # –ø—Ä–∏–º–µ–Ω—è–µ–º TTA\n            fold_logits.append(logits.cpu())\n    \n    fold_logits = torch.cat(fold_logits, dim=0)\n    all_fold_logits.append(fold_logits)\n    \n    # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏\n    del model_fold\n    torch.cuda.empty_cache()\n\nprint(\"\\nüîÑ –£—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –ø–æ –≤—Å–µ–º —Ñ–æ–ª–¥–∞–º...\")\nmean_logits = torch.mean(torch.stack(all_fold_logits), dim=0)\npred_labels = mean_logits.argmax(dim=1).tolist()\n\nsubmission[\"label\"] = pred_labels\nsubmission.to_csv(output_path, index=False)\n\nprint(f\"‚úÖ –°–∞–±–º–∏—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {output_path}\")\nprint(\"\\n–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π:\")\nsubmission.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-26T07:38:43.699473Z","iopub.execute_input":"2026-02-26T07:38:43.699801Z","iopub.status.idle":"2026-02-26T07:38:43.712153Z","shell.execute_reply.started":"2026-02-26T07:38:43.699776Z","shell.execute_reply":"2026-02-26T07:38:43.711219Z"},"id":"cNDWI7v7E63M","outputId":"c8a0625b-f3ae-404d-92c9-21e209160bf7"},"outputs":[],"execution_count":null}]}